experiment:
  # tokenizer_checkpoint: "titok_ll32_vae_c16.bin"
  output_dir: "titok3D_ll32_vae_c16"

model:
  vq_model:
    quantize_mode: "vae"
    token_size: 16
    vit_enc_model_size: "large"
    vit_dec_model_size: "large"
    vit_enc_spatial_patch_size: 16
    vit_enc_temporal_patch_size: 4
    vit_dec_spatial_patch_size: 16
    vit_dec_temporal_patch_size: 4
    num_latent_tokens: 32
    finetune_decoder: false
    is_legacy: false

dataset:
  preprocessing:
    spatial_size: 128
    temporal_size: 16
